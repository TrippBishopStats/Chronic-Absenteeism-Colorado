---
title: "Chronic Absenteeism in Colorado School Districts"
subtitle: "School years 2016-2017 to 2022-2023"
author: "Tripp Bishop"
format: html
---

```{r setup}
#| message: false
#| echo: false
library(tidyverse)
library(janitor)
library(readxl)
library(naniar)
rm(list=ls())
standard_chart_colour <- "#001970"
district_size_palette <- c("#999999", "#009E73", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_minimal())
```

## Overview
Rates of chronic absenteeism have been increasing in Colorado over the past several years. This analysis aims to identify broad trends, both spatially and temporally, in this phenomenon and to provide resources to those that are investigating and verifying methods to mitigate it.

### Objectives
The objectives of this analysis are to:

* Understand how rates of chronic absenteeism change temporally and spatially from 2016 to 2023.
* Compare chronic absenteeism rates in different regions of Colorado
* Understand if COVID-19 appears to have had a significant effect on chronic absentee rates.
* Understand if school district size is correlated with chronic absentee rates.

Data from the Colorado Department of Education will be used to understand chronic absenteeism and its rate and location of occurrence.

### Definitions
The Colorado Department of Education provides the following definition of chronic absenteeism: 

> * **Chronically Absent**: A student absent 10 percent or more of the days enrolled during the school year is chronically absent. All absences are included - unexcused and excused. The rate is the percentage of students enrolled who are chronically absent.

### Resources
The following resources were produced for this analysis and are made publicly available:

* [Chronic Absenteeism in Colorado 2016-2023 Dashboard](https://public.tableau.com/app/profile/tripp.bishop/viz/ColoradoSchoolDistrictChronicAbsenteeism/Dashboard1) - A Tableau interactive dashboard that lets the user see both spatial and temporal changes to chronic absenteeism throughout the state.

* [Chronic Absenteeism Colorado](https://github.com/TrippBishopStats/Chronic-Absenteeism-Colorado) - The github repository that contains all source materials and the code, written in the R programming language, used to produce this analysis.

## Data Sources
The data sources used in this analysis come from the Colorado Department of Education. The department maintains a website containing information about [attendance](https://www.cde.state.co.us/cdereval/truancystatistics) including information about chronic absenteeism.

The raw data for years 2016-2017 to 2021-2022 can be found at the [Attendance - Previous School Years](https://www.cde.state.co.us/cdereval/attendancedatapreviousyears) page or at the github repository listed in the [Resources](#resources) section above.

In addition to the absenteenism data, geometry files for creating maps are required for this analysis. The Colorado school district shape file was obtained from the [Colorado Geospatial Portal](https://geodata.colorado.gov/datasets/COOIT::school-districts/about) and modified to meet the needs of this analysis. From more information on how the file was modified, see the [shape file](#the-shape-file) section below.

Notes on the methodology of data collection from the Department of Education:

>* Distinct counts were taken for each level of data, i.e. distinct counts for the state, district and school level. Since distinct counts were taken, there is not necessarily a 1-1 ratio of summing up schools to equal a district count, or summing up district counts to equate state level.
* Total Days Attended + Total Days Excused + Total Days Unexcused = Total Days Possible for each student record. There is a 0.5 tolerance for this calculation.
* Chronic Absenteeism Rate adjusted from school year 2022-2023, forward, to not include PK students in denominator. 
* Total Number of Chronic Absenteeism students and Total Number of Habitually Truant (for each category) adjusted from school year 2022-2023, forward, to not include duplicate counts, i.e. not count one student twice or more for meeting multiple criteria. 
* School level data was collected up until the 2018-2019 school year with student level data collection beginning in 2019-2020.

## Data prepartion
The file structure is not consistent across the individual year datasets. There are different numbers of fields,
different names for the same fields, differing numbers of empty rows at the end of the datasets, and different file name conventions for the different datasets. The goal of the data preparation is to normalise all datasets so that they:

1) Have the same naming convention for all input files
2) Have the same structure
3) Have the same naming convention for all fields
4) Have field names that are easy to work with in code
5) Fields are in the same column order within datasets
6) Contain no extraneous records or fields
7) Ensure that all datasets contain the same number of districts

For more details on the data preparation process, consult the preparation script, `data-prep.R`, found in the `/scripts` directory of the [Chronic Absenteeism Colorado](https://github.com/TrippBishopStats/Chronic-Absenteeism-Colorado) repository.

### Standarising file names, fields, and naming conventions
The data for this analysis came in the form of Excel spreadsheets with varying
name formats. The individual school year file names were standardised with the
following format: `startyear-endyear_ChronicAbsenteeism.xslx`. For example, data
for the 2016-2017 school year is contained in the file 
`2016-2017_ChronicAbsenteeism.xlsx`.

In addition to discrepancies in file names, there were inconsistencies in the
field names between years.

The truancy data was removed from the dataset since chronic absenteeism is the
focus of this analysis. All fields were converted to "clean" names that facilitate
working with them programmatically. Differences in field names between the data
files were normalised so that all intermediate datasets have the same fields.

The changes required for each year's data are detailed in the following sections.

#### 2016-2017
* Fields were renamed to match standard names.
* Truancy field was dropped.
* The `school_year` field was missing.

#### 2017-2018/2018-2019
* Fields were renamed to match standard names.
* Truancy fields were dropped.

#### 2019-2020/2020-2021/2021-2022
* Fields were renamed to match standard names.
* Truancy fields were dropped.
* `2021_2022_student_count` field was renamed to `total_students`

### The shape file

The shape file contains all of the geometries needed to successfully create the
school districts in mapping software. The problem is that the school district
names in the file do not always match the names in the absentee datasets. There
are no other fields in the existing data to associate the district geometries
with the absentee data. Such a relationship is essential for using the data to 
create dashboards in Tableau.

To solve this problem, the `district_code` field has manually added to the
shape file to provide a simple way of creating the relationship between the
district geometries and the absentee data. In most cases, associating the correct
district code was not difficult, but the following 3 school districts required
some additional research as the district names were considerably different in
the shape file and absentee dataset.

#### School districts to repair

The following table contains the district name discrepancies.

| Absentee dataset district name  | Shapefile district name |
|---|---|
| FREMONT RE-2  | Florence RE-2 School District  |
| CUSTER COUNTY SCHOOL DISTRICT C-1  | Consolidated C-1 School District (Westcliffe)  |
| Revere School District  | Platte Valley RE-7 School District  |


```{r run data prepartion script}
# run all the preprocessing code.
source("scripts/data-prep.R")
```

## Data processing

### Understanding missingness



#### 2016-2017 school year

```{r check for missingness 2016}
naniar::miss_case_summary(df_2016) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2016 |> 
  rowid_to_column("case"), by=c("case"))
```

#### 2017-2018 school year

```{r check for missingness 2017}
naniar::miss_case_summary(df_2017) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2017 |> 
  rowid_to_column("case"), by=c("case"))
```

#### 2018-2019 school year

```{r check for missingness 2018}
naniar::miss_case_summary(df_2018) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2018 |> 
  rowid_to_column("case"), by=c("case"))
```

#### 2019-2020 school year

```{r check for missingness 2019}
naniar::miss_case_summary(df_2019) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2019 |> 
  rowid_to_column("case"), by=c("case"))
```

#### 2020-2021 school year

```{r check for missingness 2020}
naniar::miss_case_summary(df_2020) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2020 |> 
  rowid_to_column("case"), by=c("case"))
```

#### 2021-2022 school year

```{r check for missingness 2021}
naniar::miss_case_summary(df_2021) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2021 |> 
  rowid_to_column("case"), by=c("case"))
```


#### 2022-2023 school year

```{r check for missingness 2022}
naniar::miss_case_summary(df_2022) |> 
  filter(n_miss > 0) |> 
  inner_join(df_2022 |> 
  rowid_to_column("case"), by=c("case"))
```

### Merging the datasets

```{r}
df_master <- bind_rows(df_2016,
                       df_2017,
                       df_2018,
                       df_2019,
                       df_2020,
                       df_2021,
                       df_2022)
```




### Examination of unvariates

There are 3 numeric fields that need to be reviewed: `chronically_absent_rate`,
`absentee_students`, and `total_students`. All of these fields should have 
positive values. The first, `chronically_absent_rate` should range between 0 and
1. In addition to these numeric fields, the school_districts need to be examined
to ensure that all datasets include the same 178 school districts. Additionally,
each dataset should contain 178 observations for the same school year.

#### Verify counties

```{r list distinct county names}
df_master |> 
  distinct(county_name)
```
There are 63 counties present. This is good. There are 64 counties in the state, 
but Broomfield county is missing because it does not have any school districts 
of its own. It is served by existing districts.

The names are in call caps, for aesthetics, these will be converted to proper
case.

```{r verify distinct counties}
df_master <- df_master |> 
  mutate(
    county_name = str_to_title(county_name)
  )

df_master |> 
  distinct(county_name)
```

Now we need to verify the county codes.

```{r list distinct county codes} 
df_master |> 
  distinct(county_code) |> 
  pull()
```
There are 63 county codes. The data are consistent.

#### Verify school districts

Each dataset has 178 school district records. They should all be unique and 
identical between school years.

```{r distinct district count}
district_count <- df_master |>
  distinct(district_code) |> 
  count() |> 
  pull()

district_count
```
This confirms that there are only `r district_count` districts in the dataset.

```{r display distinct district name count}
district_name_count <- df_master |>
  distinct(district_name) |> 
  count() |> 
  pull()

district_name_count
```
We have an issue with the `district_name` field, however. There are `r district_name_count` distinct
values rather `r district_count`. We need to investigate the field to see if it
is possible to normalise the `district_name` field.

```{r list distinct district names}
df_master |>
  distinct(district_name)
```
After pouring through the data, it looks like the districts have both an all
caps version and a proper case version. 

```{r verify distinct school districts}

distinct_districts <- df_master |> 
  mutate(
    district_name = str_to_title(district_name)
  ) |> 
  distinct(district_name) |> 
  count() |> 
  pull()
distinct_districts
```
This gets us a lot closer. There are now only `r distinct_districts` distinct
`district_name` values, but we still have `r distinct_districts - district_count`
to normalise.

Since we know that there are only `r district_count` distinct `district_code` 
values, we can group by the `district_code` and find all instances where the
`count()` is greater than 1. There should be `r distinct_districts - district_count`
such instances.

```{r locate inconsistent district names}
df_master |> 
  mutate(
    district_name = str_to_title(district_name)
  ) |> 
  distinct(district_name, district_code) |>
  group_by(district_code) |> 
  count() |> 
  filter(n > 1)
```
These are the `r distinct_districts - district_count` districts. We can retrieve
them to see what we need to do to normalise them. Before we do, we will make
permanent the proper casing of the district names.

```{r}
df_master <- df_master |> 
  mutate(
    district_name = str_to_title(district_name)
  )

dupe_district_ids <- df_master |> 
  mutate(
    district_name = str_to_title(district_name)
  ) |> 
  distinct(district_name, district_code) |>
  group_by(district_code) |> 
  count() |> 
  filter(n > 1) |> 
  select(district_code) |> 
  pull()

df_master |> 
  filter(district_code %in% dupe_district_ids) |> 
  select(district_code, district_name) |> 
  distinct() |> 
  arrange(district_code)
```
Most of these issues are minor differences that are easily fixed. The only 
significant differences are with district codes `0920`, `1110`, `2730`, and 
`3100`. These records will need to be modified individually as there are no
patterns to the discrepancies. When the issue is that there are different names
in use, the one being used more recently will be adopted.

```{r normalise district names}

df_master <- df_master |> 
  mutate(
    district_name = case_when(district_name %in% c("Mc Clave Re-2","Mcclave Re-2") ~ "McClave Re-2",
                              str_starts(district_name, "St Vrain Valley Re") ~ "St Vrain Valley Re-1j",
                              # district 0920 is called "Elizabeth School District" most recently
                              district_name == "Elizabeth C-1" ~ "Elizabeth School District",
                              # district 1110 is called "District 49" most recently
                              district_name == "Falcon 49" ~ "District 49",
                              str_starts(district_name, "Moffat County") ~ "Moffat County Re-1",
                              district_name == "Meeker Re1" ~ "Meeker Re-1",
                              # district 2730 is called "Upper Rio Grande School District C-7" most recently
                              district_name == "Del Norte C-7" ~ "Upper Rio Grande School District C-7",
                              district_name == "Windsor Re-4" ~ "Weld Re-4",
                              # district 3140 is called "Weld Re-8 Schools" most recently
                              district_name == "Weld County S/D Re-8" ~ "Weld Re-8 Schools",
                              TRUE ~ district_name)
  )
```

This confirms that the `district_name` field has been normalised. Now there are
only `r district_count` distinct values.

```{r confirm district name normalisation}
df_master |>
  distinct(district_name) |> 
  count()
```

#### Verify school year information

Each dataset should have a single value in the `school_year` field. If this is
not the case, determine what the discrepancy is and make the correction.

```{r Verify distinct school years}
df_master |> 
  group_by(school_year) |> 
  count()
```

The datasets all contain a single value for the `school_year`.

Now that this data is confirmed, the `school_year` field should be converted to
an ordinal factor from a character field.

```{r convert school year to factor}
df_master <- df_master |> 
  mutate(
    school_year = fct_relevel(school_year, "2016-2017", "2017-2018", "2018-2019",
                              "2019-2020","2020-2021","2021-2022","2022-2023")
  )
```

#### Chronic absenteeism rate
This field represents the proportion of K-12 students who are chronically
absent. Values should range from 0 to 1 inclusive.

```{r head chronically_absent_rate}
df_master |> 
  select(chronically_absent_rate) |> 
  head()
```
This field has way too many significant figures. Most of these are meaningless 
and later years in the dataset have fewer significant figures, so the additional
significant figures will be removed by rounding.

```{r tail chronically_absent_rate}
df_master |> 
  select(chronically_absent_rate) |> 
  tail()
```
```{r round chronically_absent_rate to 3 sig figs}
df_master <- df_master |> 
  mutate(
    chronically_absent_rate = round(chronically_absent_rate, 3)
  )
```
 

```{r confirm chronic absentism rate data}
#| warning: false
df_master |> 
  ggplot(aes(x=chronically_absent_rate)) +
  geom_histogram(binwidth = 0.05, colour="white", fill=standard_chart_colour) +
  facet_wrap(~school_year) +
  labs(
    title = "Distribution of district chronic absenteeism",
    subtitle = "School years 2016-2023",
    x="Chronically absent rate",
    y="Count"
  )
```
The data look valid. There is a high occurrence of zero values in the 2016-2017 
school year. This suggests that either different school districts may have begun
record keeping at different times or that these smaller districts were actually
not seeing this phenomenon until later. Of these, the former seems more plausible.
Chronic absenteeism could be cross-referenced with truancy rates to provide a 
check on this. The truancy data may allow us to rule out the second hypothesis.
This could be done in a follow-up analysis.

There are 20 districts that reported no chronically absent students in 2016-2017.
The number steadily decreases and by 2021-2022 there are no districts reporting
no students as chronically absent.
```{r chronic absenteeism rate analysis}
df_master |> 
  filter(chronically_absent_rate == 0) |>
  ggplot(aes(x=total_students)) + 
  geom_histogram(bins=20, colour="white", fill=standard_chart_colour) +
  facet_wrap(~school_year) +
  labs(
    title = "Smaller districts are less likely to report chronic absenteeism",
    subtitle = "The number of schools not reporting declines significantly over time",
    x="Total studends enrolled",
    y="Count"
  )
```

#### Total student enrollment
The number of students enrolled in each district varies widely from less than 10
to more than 85,000. The numbers are consistent and there are no invalid values
in the dataset.

```{r total students 5 number summary}
df_master |> 
  group_by(school_year) |> 
  summarise(
    min_count = min(total_students, na.rm = TRUE),
    quartile_1 = quantile(total_students, 0.25, na.rm = TRUE),
    median = median(total_students, na.rm = TRUE),
    quartile_3 = quantile(total_students, 0.75, na.rm = TRUE),
    max_count = max(total_students, na.rm = TRUE),
  )
```

The minimum counts for the first two years look suspect. The district is the 
same in both cases, the Agate 300 school district.

```{r}
df_master |> 
  filter(total_students == 5 | total_students == 4) |> 
  select(district_code, district_name, total_students, school_year)
```

```{r}
df_master |> 
  filter(district_code == "0960")
```

The `total_students` data for Agate 300 school district is quite variable, but
5 and 4 seem like extremely low counts given the other 5 years of data 
available. It will not affect the outcome of this study, but a follow-up to
determine the true values for the 2016-2017 and 2017-2018 school years would be
useful.

```{r total students enrolled analysis}
#| message: false
df_master |>
  filter(!is.na(total_students)) |> 
  ggplot(aes(x=total_students)) +
  geom_histogram(colour="white", fill=standard_chart_colour) +
  facet_wrap(~school_year) +
  labs(
    title = "Distribution of district student enrollment",
    x="Student enrollment",
    y="Count"
  )
```

#### Chronically absent student counts
The number of chronically absent students in each district varies widely from 0
to more than 40,000. The numbers are consistent and there are no invalid values
in the dataset.

```{r absent students 5 number summary}
df_master |> 
  group_by(school_year) |> 
  summarise(
    min_count = min(absentee_students, na.rm = TRUE),
    quartile_1 = quantile(absentee_students, 0.25, na.rm = TRUE),
    median = median(absentee_students, na.rm = TRUE),
    quartile_3 = quantile(absentee_students, 0.75, na.rm = TRUE),
    max_count = max(absentee_students, na.rm = TRUE),
  )
```


```{r absentee students count analysis}
#| message: false
df_master |>
  filter(!is.na(absentee_students)) |> 
  ggplot(aes(x=absentee_students)) +
  geom_histogram(colour="white", fill=standard_chart_colour) +
  facet_wrap(~school_year) +
  labs(
      title = "Distribution of district chronic absenteeism",
      x="Absentee students",
      y="Count"
    )
```

## Feature creation
Two new features will be made from the current data: `district_size` and `pct_diff`. 
The first feature is a ordered categorical variable that describes the size of 
the district. There are five levels. From smallest to largest they are

* Micro
* Small
* Intermediate
* Medium
* Large

The second feature is the change in chronic absenteeism rate from year to year.
The values for all districts in the 2016-2017 school year are `NA` as this is
the first year in the dataset.

```{r}
df_master <- df_master |> 
  mutate(
    district_size = case_when(
      total_students > 15000 ~ "Large",
      total_students > 3000 ~ "Medium",
      total_students > 750 ~ "Intermediate",
      total_students > 100 ~ "Small",
      TRUE ~ "Micro"
    )
  ) |> 
  mutate(
    district_size = fct_relevel(district_size, "Micro", "Small", "Intermediate", "Medium", "Large")
  ) |> 
  group_by(district_code) |> 
  arrange(school_year) |> 
  mutate(
    pct_diff = chronically_absent_rate - lag(chronically_absent_rate, n=1, order_by = district_code)
  ) |>
  ungroup(district_code) |> 
  relocate(district_size, .before=chronically_absent_rate)
```

The number of districts in each group is consistent from year to year. The smaller
school districts, those in the `Small` and `Micro` categories, have the most
variability. This is not surprising as small changes in student population can 
move a district from one category to another.

```{r}
df_master |> 
  ggplot(aes(x=district_size)) +
  geom_bar(fill=standard_chart_colour) +
  facet_wrap(~school_year) +
  coord_flip() +
  labs(
    x="District size",
    y="Count"
  )
```
The `pct_diff` data looks to be consistent with what we know about the rest of
the data in this dataset. The 5 number summary shows how volatile the
absenteeism rates can be, particularly around the first COVID-19 school year
2019-2020.

```{r percent difference 5 number summary}
df_master |>
  filter(school_year != "2016-2017") |> 
  group_by(school_year) |> 
  summarise(
    min_count = min(pct_diff, na.rm = TRUE),
    quartile_1 = quantile(pct_diff, 0.25, na.rm = TRUE),
    median = median(pct_diff, na.rm = TRUE),
    quartile_3 = quantile(pct_diff, 0.75, na.rm = TRUE),
    max_count = max(pct_diff, na.rm = TRUE),
  )
```

The histograms show that the `pct_diff` data is normally distributed but with
significant outliers in the 2019-2020 and 2020-2021 school years.

```{r}
#| message: false
df_master |> 
  filter(!is.na(pct_diff)) |> 
  ggplot(aes(x=pct_diff)) +
  geom_histogram(binwidth=0.1, colour="white", fill=standard_chart_colour) +
  facet_wrap(~school_year)
```

### Create master data file
Now that the data preparation and processing have been completed, the complete
dataset can be saved to disk.

```{r write master dataframe to disk}
write_csv(df_master, file = "output/2016-2023-master_chronic_absenteeism.csv")
```

Write CSV files to output folder for each year's dataset so that they can be
reused without having to reapply the processing steps.
```{r write individual year dataframes to disk}
write_csv(df_2016, file="output/2016-2017_chronic_absenteeism.csv")
write_csv(df_2017, file="output/2017-2018_chronic_absenteeism.csv")
write_csv(df_2018, file="output/2018-2019_chronic_absenteeism.csv")
write_csv(df_2019, file="output/2019-2020_chronic_absenteeism.csv")
write_csv(df_2020, file="output/2020-2021_chronic_absenteeism.csv")
write_csv(df_2021, file="output/2021-2022_chronic_absenteeism.csv")
write_csv(df_2022, file="output/2022-2023_chronic_absenteeism.csv")
```

## Analysis






```{r absenteeism trends}
#| message: false

df_master |> 
  group_by(district_size, school_year) |> 
  summarise(
    avg_rate = sum(absentee_students, na.rm = TRUE)/sum(total_students, na.rm = TRUE)
  ) |> 
  ggplot(aes(x=school_year, y=avg_rate*100, group=district_size)) +
  geom_line(aes(colour=district_size), linewidth=1) +
  scale_colour_manual(values = district_size_palette)+
  labs(
    x=element_blank(),
    y="Percent Absentee",
    title="Absenteeism is increasing over time"
  )
```

```{r visualise enrollment pct change}
total_enrollment_year <- df_master |> 
  group_by(school_year) |> 
  summarise(
    total_enrollment = sum(total_students, na.rm = TRUE)
  )

total_enrollment_year |> 
  mutate(
    pct_change = 100*(total_enrollment - lag(total_enrollment))/lag(total_enrollment),
    pos = if_else(pct_change>0, TRUE, FALSE)
  ) |> 
  filter(school_year != "2016-2017") |> 
  ggplot(aes(x=school_year, y=pct_change, fill=pos)) +
  geom_col(position = "identity") +
  scale_fill_manual(values = c("#D6604D", "#92C5DE"), guide = FALSE) +
  labs(
    x="School year",
    y="% change",
    title="Percent change in total enrollment for Colorado",
    subtitle="2017-2023"
  )
```

```{r visual district size percentages}
#| message: false
df_master |> 
  group_by(district_size, school_year) |> 
  summarise(
    student_enrollment = sum(total_students, na.rm = TRUE)
  ) |> 
  inner_join(total_enrollment_year, by= "school_year") |> 
  mutate(
    pct_of_total = round(student_enrollment/total_enrollment,3)*100
  ) |> 
  ggplot(aes(x=fct_rev(school_year),y=pct_of_total,group=district_size, fill=district_size)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values=district_size_palette) +
  labs(
    x="School year",
    y="% of total",
    title="District size percentage of total enrollment",
    subtitle="2016-2023",
    fill="District size"
  ) +
  theme(
    legend.position = "bottom"
  )
  
```




## Key findings

* Chronic absenteeism is increasing between 2016 and 2023 with a noticeable increase in the rate of absenteeism during the COVID-19 pandemic.
* Rates of absenteeism appear to be declining, but it is too early to establish a trend.
* The pandemic appears to have caused a migration of students into and then out of larger school districts. This flux of
students may have contributed to increased rates of absenteeism during this time.
* Smaller districts generally have rate rates of absenteeism than larger ones.
* About 7 in 10 Colorado students are enrolled in large school districts. Given that these districts also have higher rates of absenteeism, State efforts to address the problem should focus on these districts








